{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a96813",
   "metadata": {},
   "source": [
    "Bài toán phân loại ung thư vú với Perceptron (SLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c66f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports & cấu hình chung\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Seed cố định để tái lập\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Thiết lập style cho biểu đồ\n",
    "plt.style.use('seaborn-v0_8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fdbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Tải dữ liệu & chuẩn hoá\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names\n",
    "\n",
    "# Chuẩn hoá StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Tách 60/20/20: train (60%), val (20%), test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=SEED, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Shapes — X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b94e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — PyTorch tensors & mô hình Perceptron\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # SLP: 1 lớp tuyến tính\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # logits, dùng BCEWithLogitsLoss\n",
    "\n",
    "model = Perceptron(input_dim=X.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Ràng buộc lr ∈ {1e-1, 1e-2}; mặc định 1e-2 (ổn định hơn)\n",
    "LR = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "MAX_EPOCHS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Huấn luyện Perceptron với SGD (epoch ≤ 50)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X_train_tensor)\n",
    "    loss = criterion(logits, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # Val loss để theo dõi\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model(X_val_tensor)\n",
    "        val_loss = criterion(val_logits, y_val_tensor).item()\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:02d}/{MAX_EPOCHS} — train_loss: {loss.item():.4f}, val_loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Đánh giá trên test set & báo cáo chỉ số\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = model(X_test_tensor)\n",
    "    test_probs = torch.sigmoid(test_logits).numpy().flatten()\n",
    "    test_preds = (test_probs >= 0.5).astype(int)\n",
    "\n",
    "# Tính chỉ số\n",
    "acc = accuracy_score(y_test, test_preds)\n",
    "prec = precision_score(y_test, test_preds)\n",
    "rec = recall_score(y_test, test_preds)\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "roc_auc = roc_auc_score(y_test, test_probs)\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "report = classification_report(y_test, test_preds, target_names=target_names)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\"],\n",
    "    \"Value\": [acc, prec, rec, f1, roc_auc]\n",
    "})\n",
    "\n",
    "print(\"Perceptron — Metrics (Test):\")\n",
    "display(metrics_df)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae88fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Vẽ ROC Curve & lưu hình\n",
    "fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Perceptron (AUC = {roc_auc:.3f})\", lw=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — Perceptron\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Ma trận nhầm lẫn & lưu hình\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "cax = ax.matshow(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix — Perceptron\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, val, ha='center', va='center')\n",
    "plt.colorbar(cax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3692907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — Nâng cao: So sánh với Logistic Regression (baseline)\n",
    "log_reg = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=1.0,\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    random_state=SEED\n",
    ")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Val để tham khảo\n",
    "val_probs_lr = log_reg.predict_proba(X_val)[:, 1]\n",
    "val_preds_lr = (val_probs_lr >= 0.5).astype(int)\n",
    "val_f1_lr = f1_score(y_val, val_preds_lr)\n",
    "\n",
    "# Test\n",
    "test_probs_lr = log_reg.predict_proba(X_test)[:, 1]\n",
    "test_preds_lr = (test_probs_lr >= 0.5).astype(int)\n",
    "acc_lr = accuracy_score(y_test, test_preds_lr)\n",
    "prec_lr = precision_score(y_test, test_preds_lr)\n",
    "rec_lr = recall_score(y_test, test_preds_lr)\n",
    "f1_lr = f1_score(y_test, test_preds_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, test_probs_lr)\n",
    "cm_lr = confusion_matrix(y_test, test_preds_lr)\n",
    "\n",
    "metrics_lr_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\"],\n",
    "    \"Perceptron\": [acc, prec, rec, f1, roc_auc],\n",
    "    \"LogisticRegression\": [acc_lr, prec_lr, rec_lr, f1_lr, roc_auc_lr]\n",
    "})\n",
    "\n",
    "print(\"So sánh Perceptron vs Logistic Regression — Metrics (Test):\")\n",
    "display(metrics_lr_df)\n",
    "\n",
    "# ROC so sánh\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, test_probs_lr)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Perceptron (AUC = {roc_auc:.3f})\", lw=2)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"LogReg (AUC = {roc_auc_lr:.3f})\", lw=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.6)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — Perceptron vs Logistic Regression\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 — Nâng cao: Phân tích đặc trưng quan trọng (coef)\n",
    "# Với Logistic Regression: hệ số là tuyến tính, dễ diễn giải\n",
    "coefs = log_reg.coef_.flatten()\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coef\": coefs,\n",
    "    \"abs_coef\": np.abs(coefs)\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top đặc trưng (theo |coef|) — Logistic Regression:\")\n",
    "display(coef_df.head(10))\n",
    "\n",
    "# Với Perceptron: lấy trọng số từ nn.Linear\n",
    "w = model.linear.weight.detach().numpy().flatten()\n",
    "b = model.linear.bias.detach().numpy().item()\n",
    "w_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"weight\": w,\n",
    "    \"abs_weight\": np.abs(w)\n",
    "}).sort_values(\"abs_weight\", ascending=False)\n",
    "\n",
    "print(\"Top đặc trưng (theo |weight|) — Perceptron:\")\n",
    "display(w_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — Lưu bảng chỉ số & báo cáo (tuỳ chọn)\n",
    "# Lưu bảng chỉ số Perceptron\n",
    "metrics_df.to_csv(\"perceptron_metrics.csv\", index=False)\n",
    "\n",
    "# Lưu classification report\n",
    "with open(\"perceptron_classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Lưu bảng so sánh\n",
    "metrics_lr_df.to_csv(\"comparison_metrics.csv\", index=False)\n",
    "\n",
    "# Lưu top đặc trưng\n",
    "coef_df.to_csv(\"logreg_feature_importance.csv\", index=False)\n",
    "w_df.to_csv(\"perceptron_feature_importance.csv\", index=False)\n",
    "\n",
    "print(\"Đã lưu các bảng chỉ số và báo cáo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d50cc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcd98e6a",
   "metadata": {},
   "source": [
    "Khi nhìn vào ROC-AUC và F1,  sẽ thấy bài toán này “mở lòng” với các mô hình tuyến tính: cấu trúc đặc trưng đã được chuẩn hoá và mối quan hệ giữa các biến với nhãn khá gần tuyến tính, nên Logistic Regression thường nhỉnh hơn hoặc tương đương Perceptron thuần SGD. Điều này hợp lý: Logistic Regression tối ưu log-loss với thuật toán cấp tiến (LBFGS) ổn định, trong khi Perceptron dùng SGD trên BCEWithLogitsLoss có thể hội tụ chậm hơn với lr nhỏ, hoặc dao động với lr lớn.\n",
    "\n",
    "Hiệu năng tổng quan: ROC-AUC thường cao (gần 0.99) trên bộ dữ liệu này. Nếu F1 và Recall cao, mô hình nhạy với ung thư ác tính — điều quan trọng về lâm sàng. Tuy nhiên Precision cũng cần giữ vững để hạn chế false positives và giảm áp lực xét nghiệm bổ sung.\n",
    "\n",
    "Ma trận nhầm lẫn: Kiểm tra số lượng FN (ác tính bị dự đoán là lành) — đây là lỗi “đau” nhất. Nếu FN thấp, mô hình đang ưu tiên an toàn cho bệnh nhân, chấp nhận thêm vài FP.\n",
    "\n",
    "So sánh mô hình: Logistic Regression thường đạt ROC-AUC và F1 nhỉnh hơn một chút. Nếu Perceptron kém hơn, thử lr = 1e-1 (vẫn trong ràng buộc) hoặc thêm weight decay rất nhỏ để ổn định; song yêu cầu bài toán không đặt nặng regularization nên giữ nguyên là hợp lệ.\n",
    "\n",
    "Đặc trưng quan trọng: Các đặc trưng liên quan đến “mean radius”, “mean texture”, “worst perimeter”, “mean concavity”, “worst concave points” thường xuất hiện với |coef| hoặc |weight| lớn. Dấu hệ số giúp ta hiểu chiều ảnh hưởng: hệ số dương đẩy xác suất về ác tính, hệ số âm về lành tính.\n",
    "\n",
    "Giới hạn: Mô hình tuyến tính không nắm bắt tương tác phi tuyến mạnh; tuy nhiên với dữ liệu này, tuyến tính đã đủ tốt. Với dữ liệu khác, có thể xem xét thêm polynomial features hoặc kernel methods.\n",
    "\n",
    "Kết luận thực tế:  Logistic Regression là ứng viên đầu tiên. Perceptron chuẩn tắc vẫn đạt tốt, và là bước khởi đầu gọn nhẹ cho việc chuyển lên các mạng sâu hơn nếu cần."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
