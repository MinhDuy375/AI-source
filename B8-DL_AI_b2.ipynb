{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34fd1e1",
   "metadata": {},
   "source": [
    "Bài 2. MLP – Phân loại chữ số MNIST\n",
    "• Bộ dữ liệu: `torchvision.datasets.MNIST` (60k train/10k test).\n",
    "• Mục tiêu: Xây MLP 2–3 tầng ẩn cho phân loại 10 lớp.\n",
    "• Nhiệm vụ:\n",
    "• Chuẩn hoá ảnh về [0,1]; flatten 28×28.\n",
    "• Kiến trúc gợi ý: 784→512→256→10; ReLU + Dropout.\n",
    "• Huấn luyện với Adam, lr=1e-3; Early stopping.\n",
    "• Báo cáo accuracy & biểu đồ loss/accuracy theo epoch.\n",
    "• Đánh giá: Top-1 Accuracy trên test; tốc độ hội tụ.\n",
    "• Ràng buộc: Epoch≤20; batch=128.\n",
    "• Sản phẩm nộp: Mã nguồn, checkpoint, biểu đồ; 1 trang phân tích overfitting/regularization.\n",
    "• Nâng cao (tuỳ chọn):\n",
    "• Thử GELU/BatchNorm.\n",
    "• Tối ưu số tầng & units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91f49a",
   "metadata": {},
   "source": [
    "# Cell 1 — Imports & cấu hình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc0ccfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "MAX_EPOCHS = 20\n",
    "PATIENCE = 3  # early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96699ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Dataset & DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # [0,1]\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # flatten 28x28 -> 784\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Tách train/val (50k/10k)\n",
    "train_size = 50000\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d83949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden1=512, hidden2=256, num_classes=10, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden2, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Training loop with Early Stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, max_epochs=20, patience=3):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "    \n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * X.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_loss /= total\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += preds.eq(y).sum().item()\n",
    "                total += y.size(0)\n",
    "        val_loss /= total\n",
    "        val_acc = correct / total\n",
    "        \n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch:02d}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, train_acc={train_acc:.4f}, val_acc={val_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"mlp_mnist_checkpoint.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    return history\n",
    "\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, MAX_EPOCHS, PATIENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf06af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Load best checkpoint & Evaluate on test\n",
    "best_model = MLP()\n",
    "best_model.load_state_dict(torch.load(\"mlp_mnist_checkpoint.pt\"))\n",
    "best_model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        outputs = best_model(X)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781f984",
   "metadata": {},
   "source": [
    "Quan sát loss/accuracy: \n",
    "\n",
    "    Trong quá trình huấn luyện, train loss giảm nhanh, train accuracy tăng mạnh. Tuy nhiên, val loss có thể ngừng giảm sớm hơn, và val accuracy có thể dừng lại hoặc giảm nhẹ sau vài epoch. Đây là dấu hiệu overfitting: mô hình học quá kỹ dữ liệu train, giảm khả năng tổng quát hóa.\n",
    "\n",
    "Regularization áp dụng:\n",
    "\n",
    "    Dropout (0.5): giúp giảm overfitting bằng cách ngẫu nhiên bỏ neuron trong quá trình huấn luyện, buộc mạng học các biểu diễn đa dạng.\n",
    "\n",
    "Early stopping: \n",
    "\n",
    "    dừng huấn luyện khi val loss không cải thiện, tránh mô hình tiếp tục overfit.\n",
    "\n",
    "Adam optimizer: \n",
    "\n",
    "    hội tụ nhanh, nhưng dễ overfit nếu không có dropout/early stopping.\n",
    "\n",
    "Kết quả: \n",
    "\n",
    "    Với kiến trúc 784→512→256→10, dropout 0.5, lr=1e-3, batch=128, mô hình thường đạt ~97–98% test accuracy trong ≤20 epoch. Đây là mức tốt cho MLP trên MNIST (CNN có thể đạt >99%).\n",
    "\n",
    "Nâng cao:\n",
    "\n",
    "\n",
    "BatchNorm: giúp ổn định phân phối kích hoạt, tăng tốc hội tụ.\n",
    "\n",
    "GELU: có thể cải thiện nhẹ so với ReLU.\n",
    "\n",
    "Tối ưu số tầng/units: giảm số units có thể giảm overfitting, tăng tốc độ.\n",
    "\n",
    "Kết luận: \n",
    "\n",
    "        MLP với dropout + early stopping đã kiểm soát overfitting khá tốt. Nếu bỏ dropout, train acc có thể đạt gần 100% nhưng val/test acc giảm. Điều này minh họa vai trò quan trọng của regularization trong mạng nơ-ron."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
